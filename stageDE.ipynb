{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0  1  2                      3       4  \\\n",
      "0   93.180.71.3  -  -  [17/May/2015:08:05:32  +0000]   \n",
      "1   93.180.71.3  -  -  [17/May/2015:08:05:23  +0000]   \n",
      "2  80.91.33.133  -  -  [17/May/2015:08:05:24  +0000]   \n",
      "3  217.168.17.5  -  -  [17/May/2015:08:05:34  +0000]   \n",
      "4  217.168.17.5  -  -  [17/May/2015:08:05:09  +0000]   \n",
      "\n",
      "                                   5    6    7  8  \\\n",
      "0  GET /downloads/product_1 HTTP/1.1  304    0  -   \n",
      "1  GET /downloads/product_1 HTTP/1.1  304    0  -   \n",
      "2  GET /downloads/product_1 HTTP/1.1  304    0  -   \n",
      "3  GET /downloads/product_1 HTTP/1.1  200  490  -   \n",
      "4  GET /downloads/product_2 HTTP/1.1  200  490  -   \n",
      "\n",
      "                                               9  \n",
      "0  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "1  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "2  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.17)  \n",
      "3                 Debian APT-HTTP/1.3 (0.8.10.3)  \n",
      "4                 Debian APT-HTTP/1.3 (0.8.10.3)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "# Откроем конкретный URL для чтения с помощью urlopen()\n",
    "response = urllib.request.urlopen('https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs')\n",
    "# Распечатаем данные ответа URL\n",
    "read_file = pd.read_csv(response, header=None, sep=\" \") \n",
    "# Создадим датафрейм на основе полученных данных\n",
    "file_to_pdb = pd.DataFrame(read_file)\n",
    "print(file_to_pdb.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем очистку данных. Удалим лишние столбцы, символы, \"склеим\" строки, которые разбились из-за того, что в качестве разделителя при чтении csv-файла применили пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51462 entries, 0 to 51461\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       51462 non-null  object\n",
      " 1   1       51462 non-null  object\n",
      " 2   2       51462 non-null  object\n",
      " 3   3       51462 non-null  object\n",
      " 4   4       51462 non-null  object\n",
      " 5   5       51462 non-null  object\n",
      " 6   6       51462 non-null  int64 \n",
      " 7   7       51462 non-null  int64 \n",
      " 8   8       51462 non-null  object\n",
      " 9   9       51462 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на структуру датафрейма\n",
    "file_to_pdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датафрейм состоит из 10 столбцов, а загрузить мы должны в таблицу в Postgres, состоящую из 5 столбцов. Очевидно, что некоторые столбцы не имеют ценности. Проверим на содержимое столбцов, которые мы хотим удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-']\n",
      "['-']\n",
      "[       0      490      337      332     3316      318      324      319\n",
      "      340     3301      335      951      334     3318     2578      339\n",
      "      331      346      336      333      328      341      345      338\n",
      "      327      329      326      325     2582     2573      322      321\n",
      "        1     2576      344     2575      342  1074411     2592     1768\n",
      "     2508 45137430      320 85619205 81860793      972      437      300\n",
      "      299      922      443      313     1288     1628      563      305\n",
      "      304      806     1837     2328      306 19077208 18443572      931\n",
      "      317 26318005    17632 64573584  1074306     3531 18497035     1464\n",
      "     1769      572   991116 69015367 26930866 86166026      182   596854\n",
      "      360 45136404  1108666 19106185     3217 19244140 26319010 19867444\n",
      "  3060803      352     9307  1073033  8526339 26917470      347      343\n",
      " 26916552 26946152 30917670      315 19849249     2267     1673 27730896\n",
      " 27967064      509     3831   368848 26318605 19076930  1069219      351\n",
      " 26952560 17668900 25350798 27734207 26948932 17600009 14814108     1909\n",
      " 12513279 41211014 14978648 26311877 26326154     3293 22897698     5635\n",
      " 82722740     1082      824 16461920 17864915  1109989  1074463  1291928\n",
      "   368847    92210    92213 27949096 19891591 63693208      221 13864207\n",
      "  6932103 20796310     1618 26315884     2673      996 17394636 17403440\n",
      " 18168295  8526358 19087515 15679478     1505     5650     4366 26333082\n",
      "      323 21273462 22901370      362      358      381      380      382\n",
      "      379      378      383      377      376      375      348     1039\n",
      "   321679 46537053 17385588      290      314 18458864 86377168 19067148\n",
      " 31614055     1081 82915969]\n",
      "['-' 'http://logstash.net/'\n",
      " 'http://www.elasticsearch.org/overview/kibana/installation/'\n",
      " 'http://www.elasticsearch.org/overview/elkdownloads/'\n",
      " 'http://www.elasticsearch.org/downloads/1-4-1/'\n",
      " 'http://www.logstash.net/'\n",
      " 'http://www.elasticsearch.org/downloads/1-3-5/'\n",
      " 'http://logstash.net/docs/1.3.3/']\n"
     ]
    }
   ],
   "source": [
    "print(file_to_pdb[1].unique())\n",
    "print(file_to_pdb[2].unique())\n",
    "print(file_to_pdb[7].unique())\n",
    "print(file_to_pdb[8].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим копию таблицы и удалим лишние столбцы\n",
    "file_to_pdb_1 = file_to_pdb.copy()\n",
    "file_to_pdb_1.drop([1, 2, 7, 8], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                          3       4  \\\n",
      "0   93.180.71.3  17/May/2015:08:05:32+0000  +0000]   \n",
      "1   93.180.71.3  17/May/2015:08:05:23+0000  +0000]   \n",
      "2  80.91.33.133  17/May/2015:08:05:24+0000  +0000]   \n",
      "3  217.168.17.5  17/May/2015:08:05:34+0000  +0000]   \n",
      "4  217.168.17.5  17/May/2015:08:05:09+0000  +0000]   \n",
      "\n",
      "                                   5    6  \\\n",
      "0  GET /downloads/product_1 HTTP/1.1  304   \n",
      "1  GET /downloads/product_1 HTTP/1.1  304   \n",
      "2  GET /downloads/product_1 HTTP/1.1  304   \n",
      "3  GET /downloads/product_1 HTTP/1.1  200   \n",
      "4  GET /downloads/product_2 HTTP/1.1  200   \n",
      "\n",
      "                                               9  \n",
      "0  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "1  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "2  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.17)  \n",
      "3                 Debian APT-HTTP/1.3 (0.8.10.3)  \n",
      "4                 Debian APT-HTTP/1.3 (0.8.10.3)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\AppData\\Local\\Temp/ipykernel_18340/2763054106.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  file_to_pdb_1[3] = file_to_pdb_1[3].str.replace('[', '')\n",
      "C:\\Users\\123\\AppData\\Local\\Temp/ipykernel_18340/2763054106.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  file_to_pdb_1[3] = file_to_pdb_1[3].str.replace(']', '')\n"
     ]
    }
   ],
   "source": [
    "# Объединим столбцы и избавимся от лишних символов\n",
    "file_to_pdb_1[3] = file_to_pdb_1[3] + file_to_pdb_1[4]\n",
    "file_to_pdb_1[3] = file_to_pdb_1[3].str.replace('[', '')\n",
    "file_to_pdb_1[3] = file_to_pdb_1[3].str.replace(']', '')\n",
    "print(file_to_pdb_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                          3                                  5  \\\n",
      "0   93.180.71.3  17/May/2015:08:05:32+0000  GET /downloads/product_1 HTTP/1.1   \n",
      "1   93.180.71.3  17/May/2015:08:05:23+0000  GET /downloads/product_1 HTTP/1.1   \n",
      "2  80.91.33.133  17/May/2015:08:05:24+0000  GET /downloads/product_1 HTTP/1.1   \n",
      "3  217.168.17.5  17/May/2015:08:05:34+0000  GET /downloads/product_1 HTTP/1.1   \n",
      "4  217.168.17.5  17/May/2015:08:05:09+0000  GET /downloads/product_2 HTTP/1.1   \n",
      "\n",
      "     6                                              9  \n",
      "0  304  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "1  304  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)  \n",
      "2  304  Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.17)  \n",
      "3  200                 Debian APT-HTTP/1.3 (0.8.10.3)  \n",
      "4  200                 Debian APT-HTTP/1.3 (0.8.10.3)  \n"
     ]
    }
   ],
   "source": [
    "# Удалим столбец, который мы присоединили\n",
    "file_to_pdb_1.drop([4], axis=1, inplace=True)\n",
    "print(file_to_pdb_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем столбец с датой к типу datetime, предварительно удалив лишний знак \":\"\n",
    "file_to_pdb_1[3] = file_to_pdb_1[3].str.replace(':', ' ', 1)\n",
    "file_to_pdb_1[3] = pd.to_datetime(file_to_pdb_1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2015-05-17 08:05:32+00:00\n",
      "1       2015-05-17 08:05:23+00:00\n",
      "2       2015-05-17 08:05:24+00:00\n",
      "3       2015-05-17 08:05:34+00:00\n",
      "4       2015-05-17 08:05:09+00:00\n",
      "                   ...           \n",
      "51457   2015-06-04 07:06:04+00:00\n",
      "51458   2015-06-04 07:06:05+00:00\n",
      "51459   2015-06-04 07:06:16+00:00\n",
      "51460   2015-06-04 07:06:05+00:00\n",
      "51461   2015-06-04 07:06:35+00:00\n",
      "Name: 3, Length: 51462, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "print(file_to_pdb_1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем столбцы\n",
    "file_to_pdb_1.columns = ['ip', 'time', 'request', 'error_code', 'system_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим тип данных на строку\n",
    "file_to_pdb_1['error_code'] = file_to_pdb_1['error_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Table logs has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Загрузим наш датафрейм в базу данных\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 \n",
    "import io\n",
    "engine = create_engine('postgresql+psycopg2://postgres:1234@127.0.0.1/postgres')\n",
    "postgreSQLConnection = engine.connect()\n",
    "postgreSQLTable = \"logs\"\n",
    "\n",
    "try:\n",
    "\n",
    "    frame  = file_to_pdb_1.to_sql(postgreSQLTable, postgreSQLConnection, if_exists='append', index=False);\n",
    "\n",
    "except ValueError as vx:\n",
    "\n",
    "    print(vx)\n",
    "\n",
    "except Exception as ex:  \n",
    "\n",
    "    print(ex)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"PostgreSQL Table %s has been created successfully.\"%postgreSQLTable);\n",
    "\n",
    "finally:\n",
    "\n",
    "    postgreSQLConnection.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_to_pdb_1.to_csv('from_posgres_db.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e052d4e0222e7fe77152d0a9dc2d2af05426cb5296a6b56fda7b6c53ad5778b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
